{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMaZ/e9M5MVN9viB/gz5Azl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ak-Gautam/AudioDataPrerocess/blob/main/Audio.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Get data in local file."
      ],
      "metadata": {
        "id": "tUFAjP4HY80N"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4t_NLceuX__L"
      },
      "outputs": [],
      "source": [
        "!pip install aiohttp aiofiles huggingface_hub -q"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import asyncio\n",
        "import aiohttp\n",
        "import aiofiles\n",
        "from huggingface_hub import hf_hub_url, HfApi\n",
        "from tqdm.asyncio import tqdm_asyncio"
      ],
      "metadata": {
        "id": "DX5ZkRX9Y4bU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "async def download_file(session, file, repo_id, repo_type, destination_dir, semaphore):\n",
        "    async with semaphore:\n",
        "        file_url = hf_hub_url(repo_id, file, repo_type=repo_type)\n",
        "        dest_path = os.path.join(destination_dir, file)\n",
        "        os.makedirs(os.path.dirname(dest_path), exist_ok=True)\n",
        "\n",
        "        async with session.get(file_url) as response:\n",
        "            if response.status == 200:\n",
        "                async with aiofiles.open(dest_path, 'wb') as f:\n",
        "                    await f.write(await response.read())\n",
        "            else:\n",
        "                print(f\"Failed to download {file}: HTTP {response.status}\")\n",
        "\n",
        "async def download_dataset(repo_id, repo_type, folder_path, destination_dir, max_concurrent=10):\n",
        "    api = HfApi()\n",
        "    all_files = api.list_repo_files(repo_id, repo_type=repo_type)\n",
        "    folder_files = [f for f in all_files if f.startswith(folder_path)]\n",
        "\n",
        "    semaphore = asyncio.Semaphore(max_concurrent)\n",
        "    async with aiohttp.ClientSession() as session:\n",
        "        tasks = [\n",
        "            download_file(session, file, repo_id, repo_type, destination_dir, semaphore)\n",
        "            for file in folder_files\n",
        "        ]\n",
        "        await tqdm_asyncio.gather(*tasks, desc=\"Downloading files\")\n",
        "\n",
        "# Configuration\n",
        "repo_id = \"Alignment-Lab-AI/podcast-1-test-preprocessed\"\n",
        "repo_type = \"dataset\"\n",
        "folder_path = \"0\"\n",
        "destination_dir = \"content/ddata\"\n",
        "\n",
        "# Run the async function\n",
        "async def main():\n",
        "    await download_dataset(repo_id, repo_type, folder_path, destination_dir)\n",
        "    print(f\"Folder '{folder_path}' from repository '{repo_id}' has been saved to '{destination_dir}'\")\n",
        "\n",
        "# This part is changed to work in Jupyter/Colab\n",
        "import nest_asyncio\n",
        "nest_asyncio.apply()\n",
        "\n",
        "loop = asyncio.get_event_loop()\n",
        "loop.run_until_complete(main())"
      ],
      "metadata": {
        "id": "tfpkx_0OY6RL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Processing starts from here!"
      ],
      "metadata": {
        "id": "bU1prri-ZCRr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pydub -q"
      ],
      "metadata": {
        "id": "Kp05mwUMtt_x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download a static FFmpeg build and add it to PATH.\n",
        "exist = !which ffmpeg\n",
        "if not exist:\n",
        "  !curl https://johnvansickle.com/ffmpeg/releases/ffmpeg-release-amd64-static.tar.xz -o ffmpeg.tar.xz \\\n",
        "     && tar -xf ffmpeg.tar.xz && rm ffmpeg.tar.xz\n",
        "  ffmdir = !find . -iname ffmpeg-*-static\n",
        "  path = %env PATH\n",
        "  path = path + ':' + ffmdir[0]\n",
        "  %env PATH $path\n",
        "print('')\n",
        "!which ffmpeg\n",
        "print('Done!')"
      ],
      "metadata": {
        "id": "GY65OdJxZFH_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pydub import AudioSegment\n",
        "\n",
        "spacermilli = 2000\n",
        "spacer = AudioSegment.silent(duration=spacermilli)\n",
        "\n",
        "audio = AudioSegment.from_mp3(\"content/ddata/0/10.mp3\")\n",
        "\n",
        "audio = spacer.append(audio, crossfade=0)\n",
        "\n",
        "audio.export('input_prep.wav', format='wav')"
      ],
      "metadata": {
        "id": "KDZoM_b7tzbA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install light-the-torch -q\n",
        "!ltt install torch torchvision torchaudio -q"
      ],
      "metadata": {
        "id": "DZdfYK6qjh0A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyannote.audio -q"
      ],
      "metadata": {
        "id": "v-w0F8zGt24A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyannote.audio import Pipeline\n",
        "pipeline = Pipeline.from_pretrained('pyannote/speaker-diarization-3.1', use_auth_token='')"
      ],
      "metadata": {
        "id": "tnjw5eNGkBPU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "pipeline.to(device)"
      ],
      "metadata": {
        "id": "HSLkaTLIkBw-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DEMO_FILE = {'uri': 'blabla', 'audio': 'input_prep.wav'}\n",
        "dz = pipeline('input_prep.wav')\n",
        "\n",
        "with open(\"diarization.txt\", \"w\") as text_file:\n",
        "    text_file.write(str(dz))"
      ],
      "metadata": {
        "id": "K78EKuBekEdV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(*list(dz.itertracks(yield_label = True))[:10], sep=\"\\n\")"
      ],
      "metadata": {
        "id": "LycabF0SkGaO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}